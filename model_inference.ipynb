{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference\n",
    "\n",
    "1. Download model and batch inference data\n",
    "2. Make predictions\n",
    "3. Store predictions in a monitoring feature group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 19:33:22,080 INFO: Closing external client and cleaning up certificates.\n",
      "2026-01-11 19:33:22,081 INFO: Connection closed.\n",
      "2026-01-11 19:33:22,083 INFO: Initializing external client\n",
      "2026-01-11 19:33:22,084 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-11 19:33:22,944 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/2173\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import xgboost as xgb\n",
    "import unicodedata\n",
    "import re\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# connect with Hopsworks\n",
    "project = hopsworks.login(\n",
    "        host=\"eu-west.cloud.hopsworks.ai\",\n",
    "        project=\"ID2223_Project\",\n",
    "        api_key_value=os.environ[\"HOPSWORKS_API_KEY\"]\n",
    "    )\n",
    "\n",
    "# Get feature view\n",
    "fs = project.get_feature_store()\n",
    "fv = fs.get_feature_view('avalanche_warning_fv_new_corrected_more_features_and_lags', version=5)\n",
    "\n",
    "# Get model registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_name(name):\n",
    "    # Normalize Unicode to ASCII, ignore accents\n",
    "    name_ascii = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore').decode()\n",
    "    # Replace anything not a-z, A-Z, 0-9, or _ with underscore\n",
    "    name_clean = re.sub(r'[^a-zA-Z0-9_]', '_', name_ascii)\n",
    "    return name_clean\n",
    "\n",
    "def predict(model: xgb.XGBRegressor, features_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Predict avalanche risk\n",
    "    \"\"\"\n",
    "    features_df = features_df.astype(float)\n",
    "    return float(model.predict(features_df)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (6.95s) \n"
     ]
    }
   ],
   "source": [
    "# Create batch data for the feature view\n",
    "batch_data = fv.get_batch_data(dataframe_type=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download models from Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for Sauda Ski Centre...\n",
      "Model(name: 'xgb_avalanche_model_Sauda_Ski_Centre', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1dbe63610e4547a21fafd43636f10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/396651 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Sauda Ski Centre loaded successfullyDONE\n",
      "\n",
      "Loading model for Hemsedal Skisenter...\n",
      "Model(name: 'xgb_avalanche_model_Hemsedal_Skisenter', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f172ba2bca347fba8fe408086b27fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/335400 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Hemsedal Skisenter loaded successfullyNE\n",
      "\n",
      "Loading model for Eikedalen Ski Center AS...\n",
      "Model(name: 'xgb_avalanche_model_Eikedalen_Ski_Center_AS', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cdc22330874427adc6003c43191825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/366544 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Eikedalen Ski Center AS loaded successfully\n",
      "\n",
      "Loading model for Myrkdalen Fjellandsby...\n",
      "Model(name: 'xgb_avalanche_model_Myrkdalen_Fjellandsby', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101cc0b1abbd4069adc8329218ba6133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/267407 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Myrkdalen Fjellandsby loaded successfully\n",
      "\n",
      "Loading model for Rauland Skisenter...\n",
      "Model(name: 'xgb_avalanche_model_Rauland_Skisenter', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5549a616ee4142cbaaebaa19ac30cffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/386919 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Rauland Skisenter loaded successfullyONE\n",
      "\n",
      "Loading model for Bjorli Ski...\n",
      "Model(name: 'xgb_avalanche_model_Bjorli_Ski', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cfe0d2076c494f87d3b93bca7fa14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/399508 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Bjorli Ski loaded successfullys)... DONE\n",
      "\n",
      "Loading model for Strandafjellet Skisenter...\n",
      "Model(name: 'xgb_avalanche_model_Strandafjellet_Skisenter', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3830ecf387754b22b827872abf304c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/366828 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Strandafjellet Skisenter loaded successfully\n",
      "\n",
      "Loading model for Voss Resort Fjellheisar...\n",
      "Model(name: 'xgb_avalanche_model_Voss_Resort_Fjellheisar', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daa1600d3c64ed5bb36bf9ecd79461d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/601204 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Voss Resort Fjellheisar loaded successfully\n",
      "\n",
      "Loading model for Galdhøpiggen Summer Ski Centre...\n",
      "Model(name: 'xgb_avalanche_model_Galdhpiggen_Summer_Ski_Centre', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2040fec0d72c463caebb28b35d7eb682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/393030 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Galdhøpiggen Summer Ski Centre loaded successfully\n",
      "\n",
      "Loading model for Hovden Alpinsenter...\n",
      "Model(name: 'xgb_avalanche_model_Hovden_Alpinsenter', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b66e3c944f4aa5b47a4bdbed12e861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/335007 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Hovden Alpinsenter loaded successfullyNE\n",
      "\n",
      "Loading model for Narvik Ski Resort...\n",
      "Model(name: 'xgb_avalanche_model_Narvik_Ski_Resort', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fdec5879934f7ba4482cbaafb71537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/155542 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Narvik Ski Resort loaded successfullyONE\n",
      "\n",
      "Loading model for Nedre fjellheisstasjon Narvik...\n",
      "Model(name: 'xgb_avalanche_model_Nedre_fjellheisstasjon_Narvik', version: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31406abc5c064b8d8ab852438a9cacdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/368873 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model for Nedre fjellheisstasjon Narvik loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "#Retrieve the name resorts\n",
    "resorts = {loc: None for loc in batch_data[\"location\"].unique()}\n",
    "\n",
    "models = {}           \n",
    "model_dirs = {}      \n",
    "\n",
    "for loc in resorts.keys():  \n",
    "    loc_ = sanitize_name(loc.replace(\" \", \"_\"))\n",
    "    print(f\"Loading model for {loc}...\")\n",
    "\n",
    "    # Retrieve model from registry\n",
    "    model = mr.get_model(\n",
    "        name=f\"xgb_avalanche_model_{loc_}\",\n",
    "        version=3  \n",
    "    )\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    # Download model artifacts\n",
    "    model_dir = model.download()\n",
    "\n",
    "    # Load XGBoost model\n",
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model.load_model(\n",
    "        f\"{model_dir}/xgb_ordinal_model_more_features{loc_}.json\"\n",
    "    )\n",
    "\n",
    "    # Store everything\n",
    "    models[loc] = xgb_model\n",
    "    model_dirs[loc] = model_dir\n",
    "\n",
    "    print(f\"✓ Model for {loc} loaded successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Weather Forecast Features with Feature View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.84s) \n"
     ]
    }
   ],
   "source": [
    "# Feature group for weather\n",
    "aq_fg = fs.get_feature_group(\n",
    "    name='weather_terrain_sensor',\n",
    "    version=2,\n",
    ")\n",
    "\n",
    "aq_df = aq_fg.read().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort batch data by date\n",
    "batch_data_sorted = batch_data.sort_values(\n",
    "    by=\"date\", \n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "# DataFrame of resorts considering only the most recent data\n",
    "latest_7_per_location_weather = (\n",
    "    aq_df\n",
    "    .sort_values(\"date\", ascending=False)\n",
    "    .groupby(\"location\", as_index=False)\n",
    "    .head(7)\n",
    ")\n",
    "\n",
    "# Get todays value first\n",
    "latest_7_per_location_weather = (latest_7_per_location_weather.sort_values(by=\"date\",ascending=True))   \n",
    "\n",
    "# DataFrame for the latest warnings for each resort\n",
    "a = len(resorts)\n",
    "df_warning_lag = batch_data_sorted.head(a)\n",
    "\n",
    "# Dictionary to hold a DataFrame for each location\n",
    "dfs_per_location = {}\n",
    "\n",
    "# Loop over unique locations\n",
    "for i, location in enumerate(latest_7_per_location_weather['location'].unique()):\n",
    "    loc_ = sanitize_name(location)\n",
    "    # Create a copy for the dictionary\n",
    "    dfs_per_location[location] = latest_7_per_location_weather[latest_7_per_location_weather['location'] == location].copy()\n",
    "    \n",
    "    # Dynamically create a variable for each dataframe\n",
    "    globals()[f'df_location_{loc_}'] = dfs_per_location[location]\n",
    "\n",
    "# Feature columns\n",
    "feature_cols = [\n",
    "    \"warning_level_lag_1\", \n",
    "    \"warning_level_lag_2\",\n",
    "    \"warning_level_lag_3\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"precipitation_sum\",\n",
    "    \"rain_sum\",\n",
    "    \"snowfall_sum\",\n",
    "    \"wind_speed_10m_max\",\n",
    "    \"wind_direction_10m_dominant\",\n",
    "    \"snow_load_steep\",\n",
    "    \"wind_snow_transport\",\n",
    "    \"rain_on_snow_risk\",\n",
    "    \"temp_elev\",\n",
    "    \"precip_slope_weighted\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the lag features for today per location\n",
    "for location in resorts.keys():\n",
    "    loc_ = sanitize_name(location.replace(\" \", \"_\"))\n",
    "    df_name = f'df_location_{loc_}'\n",
    "    df = globals()[df_name]\n",
    "\n",
    "    #Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df['warning_level_lag_1'] = np.nan\n",
    "    df['warning_level_lag_2'] = np.nan\n",
    "    df['warning_level_lag_3'] = np.nan\n",
    "\n",
    "    df_warning_lag_idx = df_warning_lag.set_index('location')\n",
    "\n",
    "    if location in df_warning_lag_idx.index:\n",
    "        df.loc[df.index[0],\n",
    "               ['warning_level_lag_1',\n",
    "                'warning_level_lag_2',\n",
    "                'warning_level_lag_3']] = (\n",
    "            df_warning_lag_idx.loc[location,\n",
    "                ['warning_level_lag_1',\n",
    "                 'warning_level_lag_2',\n",
    "                 'warning_level_lag_3']]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in resorts.keys():\n",
    "    loc_ = sanitize_name(location.replace(\" \", \"_\"))\n",
    "    df = globals()[f'df_location_{loc_}']\n",
    "\n",
    "    # Initialize lags from first row\n",
    "    lag_1 = df.loc[0, 'warning_level_lag_1']\n",
    "    lag_2 = df.loc[0, 'warning_level_lag_2']\n",
    "    lag_3 = df.loc[0, 'warning_level_lag_3']\n",
    "\n",
    "    for i, idx in enumerate(df.index[:7]):\n",
    "\n",
    "        # Assign current lags to this row\n",
    "        df.loc[idx, 'warning_level_lag_1'] = lag_1\n",
    "        df.loc[idx, 'warning_level_lag_2'] = lag_2\n",
    "        df.loc[idx, 'warning_level_lag_3'] = lag_3\n",
    "\n",
    "        # Build features\n",
    "        features = df.loc[[idx], feature_cols]\n",
    "\n",
    "        # Predict\n",
    "        prediction = predict(models[location], features)\n",
    "        df.loc[i, 'predicted_risk_value'] = prediction\n",
    "\n",
    "        # Shift lags for next day\n",
    "        lag_3, lag_2, lag_1 = lag_2, lag_1, prediction\n",
    "        df['days_before_forecast_day'] = range(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store prediction values into feature stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_fg_name(name):\n",
    "    # lowercase, replace spaces and non-alphanum with _\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'[^a-z0-9]', '_', name)\n",
    "    name = re.sub(r'_+', '_', name)  # collapse multiple underscores\n",
    "    name = name.strip('_')  # remove leading/trailing underscores\n",
    "    return name[:63]  # truncate to 63 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 19:33:46,246 INFO: Computing insert statistics\n",
      "2026-01-11 19:34:03,730 INFO: Computing insert statistics\n",
      "2026-01-11 19:34:20,736 INFO: Computing insert statistics\n",
      "2026-01-11 19:34:37,814 INFO: Computing insert statistics\n",
      "2026-01-11 19:34:54,443 INFO: Computing insert statistics\n",
      "2026-01-11 19:35:11,454 INFO: Computing insert statistics\n",
      "2026-01-11 19:35:28,389 INFO: Computing insert statistics\n",
      "2026-01-11 19:35:45,366 INFO: Computing insert statistics\n",
      "2026-01-11 19:36:02,263 INFO: Computing insert statistics\n",
      "2026-01-11 19:36:19,071 INFO: Computing insert statistics\n",
      "2026-01-11 19:36:36,542 INFO: Computing insert statistics\n",
      "2026-01-11 19:36:53,739 INFO: Computing insert statistics\n"
     ]
    }
   ],
   "source": [
    "for location in resorts.keys():\n",
    "    loc_ = sanitize_name(location.replace(\" \", \"_\"))\n",
    "    fg_name = sanitize_fg_name(f'aq_predictions_{loc_}')\n",
    "\n",
    "    monitor_fg = fs.get_or_create_feature_group(\n",
    "        name=fg_name,\n",
    "        description='Avalanche prediction monitoring with lags',\n",
    "        version=1,\n",
    "        primary_key=['location', 'date', 'days_before_forecast_day'],\n",
    "        event_time='date'\n",
    "    )\n",
    "\n",
    "    df = globals()[f'df_location_{loc_}']\n",
    "    monitor_fg.insert(df, wait=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.14 ('mlpj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e7b96798f6eda4112476d75a42a1c55b0529cbbe293a7d162df97018d67f067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
